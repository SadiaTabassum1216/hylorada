{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# HyLoRADA Unified (v0.3.0)\n",
                "\n",
                "Parameter-efficient fine-tuning for long-context LLMs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repo\n",
                "!git clone https://github.com/SadiaTabassum1216/hylorada.git\n",
                "%cd hylorada"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q transformers datasets accelerate tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU\n",
                "import torch\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test imports\n",
                "from hylorada import HyLoRADAConfig, HyLoRADAModel\n",
                "config = HyLoRADAConfig(lora_rank=8)\n",
                "print(\"Config:\", config.get_component_status())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run Benchmark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python run_benchmark.py --methods lora hylorada --epochs 3 --num_train 500"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train on Code"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python run_code_task.py --epochs 3 --rank 8"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json, os, glob\n",
                "\n",
                "for f in glob.glob('./**/benchmark*.json', recursive=True):\n",
                "    print(f\"\\n=== {f} ===\")\n",
                "    data = json.load(open(f))\n",
                "    if 'results' in data:\n",
                "        for m, r in data['results'].items():\n",
                "            if 'perplexity' in r:\n",
                "                print(f\"{m}: PPL={r['perplexity']:.2f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "kaggle": {
            "accelerator": "gpu",
            "isGpuEnabled": true,
            "isInternetEnabled": true
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}