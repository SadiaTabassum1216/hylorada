{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e12b2343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T07:28:53.285798Z",
     "iopub.status.busy": "2026-01-15T07:28:53.285054Z",
     "iopub.status.idle": "2026-01-15T07:28:53.291678Z",
     "shell.execute_reply": "2026-01-15T07:28:53.291138Z"
    },
    "papermill": {
     "duration": 0.011438,
     "end_time": "2026-01-15T07:28:53.293050",
     "exception": false,
     "start_time": "2026-01-15T07:28:53.281612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Suppress TensorFlow/protobuf warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['GRPC_VERBOSITY'] = 'ERROR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842fe43d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T07:28:53.297010Z",
     "iopub.status.busy": "2026-01-15T07:28:53.296555Z",
     "iopub.status.idle": "2026-01-15T07:28:54.072733Z",
     "shell.execute_reply": "2026-01-15T07:28:54.071726Z"
    },
    "papermill": {
     "duration": 0.779684,
     "end_time": "2026-01-15T07:28:54.074241",
     "exception": false,
     "start_time": "2026-01-15T07:28:53.294557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'hylorada'...\r\n",
      "remote: Enumerating objects: 73, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (73/73), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (49/49), done.\u001b[K\r\n",
      "remote: Total 73 (delta 38), reused 57 (delta 22), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (73/73), 129.40 KiB | 7.19 MiB/s, done.\r\n",
      "Resolving deltas: 100% (38/38), done.\r\n",
      "/kaggle/working/hylorada\n"
     ]
    }
   ],
   "source": [
    "# Clone repo\n",
    "!git clone https://github.com/SadiaTabassum1216/hylorada.git\n",
    "%cd hylorada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83dc3b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T07:28:54.078865Z",
     "iopub.status.busy": "2026-01-15T07:28:54.078623Z",
     "iopub.status.idle": "2026-01-15T07:28:58.563609Z",
     "shell.execute_reply": "2026-01-15T07:28:58.562575Z"
    },
    "papermill": {
     "duration": 4.48951,
     "end_time": "2026-01-15T07:28:58.565503",
     "exception": false,
     "start_time": "2026-01-15T07:28:54.075993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ce4c2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T07:28:58.570809Z",
     "iopub.status.busy": "2026-01-15T07:28:58.570535Z",
     "iopub.status.idle": "2026-01-15T07:29:02.232903Z",
     "shell.execute_reply": "2026-01-15T07:29:02.231996Z"
    },
    "papermill": {
     "duration": 3.667214,
     "end_time": "2026-01-15T07:29:02.234522",
     "exception": false,
     "start_time": "2026-01-15T07:28:58.567308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec81a51b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T07:29:02.239228Z",
     "iopub.status.busy": "2026-01-15T07:29:02.238830Z",
     "iopub.status.idle": "2026-01-15T07:29:02.242364Z",
     "shell.execute_reply": "2026-01-15T07:29:02.241729Z"
    },
    "papermill": {
     "duration": 0.007489,
     "end_time": "2026-01-15T07:29:02.243737",
     "exception": false,
     "start_time": "2026-01-15T07:29:02.236248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python run_experiment.py --model_name Qwen/Qwen2-0.5B --max_length 1024 --num_epochs 1 --num_test_samples 20 --gradient_accumulation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fe5a58f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T07:29:02.248067Z",
     "iopub.status.busy": "2026-01-15T07:29:02.247554Z",
     "iopub.status.idle": "2026-01-15T08:18:52.920112Z",
     "shell.execute_reply": "2026-01-15T08:18:52.919381Z"
    },
    "papermill": {
     "duration": 2990.67666,
     "end_time": "2026-01-15T08:18:52.921948",
     "exception": false,
     "start_time": "2026-01-15T07:29:02.245288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\r\n",
      "PEFT Method Comparison Experiment\r\n",
      "======================================================================\r\n",
      "Model: Qwen/Qwen2-0.5B\r\n",
      "Methods: baseline, lora, lorada, longlora, sparse, hylorada\r\n",
      "Max Length: 1024\r\n",
      "Epochs: 1\r\n",
      "Output: ./experiments/comparison_20260115_072915\r\n",
      "======================================================================\r\n",
      "\r\n",
      "[1] Loading tokenizer...\r\n",
      "tokenizer_config.json: 1.29kB [00:00, 4.55MB/s]\r\n",
      "vocab.json: 2.78MB [00:00, 76.0MB/s]\r\n",
      "merges.txt: 1.67MB [00:00, 135MB/s]\r\n",
      "tokenizer.json: 7.03MB [00:00, 181MB/s]\r\n",
      "\r\n",
      "[2] Preparing data...\r\n",
      "README.md: 10.5kB [00:00, 38.8MB/s]\r\n",
      "wikitext-2-raw-v1/test-00000-of-00001.pa(…): 100%|█| 733k/733k [00:00<00:00, 1.2\r\n",
      "wikitext-2-raw-v1/train-00000-of-00001.p(…): 100%|█| 6.36M/6.36M [00:00<00:00, 1\r\n",
      "wikitext-2-raw-v1/validation-00000-of-00(…): 100%|█| 657k/657k [00:00<00:00, 3.0\r\n",
      "Generating test split: 100%|█████| 4358/4358 [00:00<00:00, 103642.92 examples/s]\r\n",
      "Generating train split: 100%|██| 36718/36718 [00:00<00:00, 736791.90 examples/s]\r\n",
      "Generating validation split: 100%|█| 3760/3760 [00:00<00:00, 613545.87 examples/\r\n",
      "    Train samples: 1000, Test samples: 100\r\n",
      "\r\n",
      "[3] Running BASELINE...\r\n",
      "--------------------------------------------------\r\n",
      "  Loading fresh model...\r\n",
      "config.json: 100%|█████████████████████████████| 661/661 [00:00<00:00, 5.00MB/s]\r\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1768462164.061951      61 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1768462164.112995      61 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "W0000 00:00:1768462164.540146      61 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768462164.540205      61 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768462164.540214      61 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768462164.540227      61 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "model.safetensors: 100%|██████████████████████| 988M/988M [00:03<00:00, 284MB/s]\r\n",
      "generation_config.json: 100%|███████████████████| 138/138 [00:00<00:00, 840kB/s]\r\n",
      "  Evaluating baseline...\r\n",
      "    Evaluating perplexity...\r\n",
      "Evaluating: 100%|█████████████████████████████| 100/100 [00:08<00:00, 11.57it/s]\r\n",
      "    Evaluating lost-in-middle...\r\n",
      "Lost-in-Middle Analysis: 100%|██████████████████| 20/20 [00:01<00:00, 16.66it/s]\r\n",
      "  ✗ Error with baseline: unsupported format string passed to EvaluationResult.__format__\r\n",
      "\r\n",
      "[4] Running LORA...\r\n",
      "--------------------------------------------------\r\n",
      "  Loading fresh model...\r\n",
      "============================================================\r\n",
      "Standard LoRA Parameter Summary\r\n",
      "============================================================\r\n",
      "Total parameters:     494,573,440\r\n",
      "Trainable parameters: 540,672\r\n",
      "Trainable ratio:      0.1093%\r\n",
      "------------------------------------------------------------\r\n",
      "  LoRA: 540,672\r\n",
      "============================================================\r\n",
      "\r\n",
      "  Training LoRA...\r\n",
      "Starting training for 1 epochs\r\n",
      "Total steps: 62\r\n",
      "Device: cuda\r\n",
      "Epoch 1: 100%|████| 1000/1000 [08:59<00:00,  1.86it/s, loss=4.2231, lr=3.93e-05]\r\n",
      "  Evaluating lora...\r\n",
      "    Evaluating perplexity...\r\n",
      "Evaluating: 100%|█████████████████████████████| 100/100 [00:08<00:00, 12.01it/s]\r\n",
      "    Evaluating lost-in-middle...\r\n",
      "Lost-in-Middle Analysis: 100%|██████████████████| 20/20 [00:01<00:00, 16.04it/s]\r\n",
      "  ✗ Error with lora: unsupported format string passed to EvaluationResult.__format__\r\n",
      "\r\n",
      "[5] Running LORADA...\r\n",
      "--------------------------------------------------\r\n",
      "  Loading fresh model...\r\n",
      "============================================================\r\n",
      "LoRaDA Parameter Summary\r\n",
      "============================================================\r\n",
      "Total parameters:     495,114,784\r\n",
      "Trainable parameters: 1,082,016\r\n",
      "Trainable ratio:      0.2185%\r\n",
      "------------------------------------------------------------\r\n",
      "  LoRA: 1,081,344\r\n",
      "  DAA:  672\r\n",
      "============================================================\r\n",
      "\r\n",
      "  Training LoRaDA...\r\n",
      "Starting training for 1 epochs\r\n",
      "Total steps: 62\r\n",
      "Device: cuda\r\n",
      "Epoch 1: 100%|████| 1000/1000 [09:31<00:00,  1.75it/s, loss=2.7686, lr=3.93e-05]\r\n",
      "  Evaluating lorada...\r\n",
      "    Evaluating perplexity...\r\n",
      "Evaluating: 100%|█████████████████████████████| 100/100 [00:08<00:00, 11.64it/s]\r\n",
      "    Evaluating lost-in-middle...\r\n",
      "Lost-in-Middle Analysis: 100%|██████████████████| 20/20 [00:01<00:00, 15.47it/s]\r\n",
      "  ✗ Error with lorada: unsupported format string passed to EvaluationResult.__format__\r\n",
      "\r\n",
      "[6] Running LONGLORA...\r\n",
      "--------------------------------------------------\r\n",
      "  Loading fresh model...\r\n",
      "============================================================\r\n",
      "LongLoRA Parameter Summary\r\n",
      "============================================================\r\n",
      "Total parameters:     495,114,112\r\n",
      "Trainable parameters: 137,259,904\r\n",
      "Trainable ratio:      27.7229%\r\n",
      "------------------------------------------------------------\r\n",
      "  LoRA:       1,081,344\r\n",
      "  Embeddings: 136,134,656\r\n",
      "  LayerNorms: 43,904\r\n",
      "============================================================\r\n",
      "\r\n",
      "  Training LongLoRA...\r\n",
      "Starting training for 1 epochs\r\n",
      "Total steps: 62\r\n",
      "Device: cuda\r\n",
      "Epoch 1: 100%|████| 1000/1000 [10:20<00:00,  1.61it/s, loss=2.0171, lr=3.93e-05]\r\n",
      "  Evaluating longlora...\r\n",
      "    Evaluating perplexity...\r\n",
      "Evaluating: 100%|█████████████████████████████| 100/100 [00:08<00:00, 11.60it/s]\r\n",
      "    Evaluating lost-in-middle...\r\n",
      "Lost-in-Middle Analysis: 100%|██████████████████| 20/20 [00:01<00:00, 15.59it/s]\r\n",
      "  ✗ Error with longlora: unsupported format string passed to EvaluationResult.__format__\r\n",
      "\r\n",
      "[7] Running SPARSE...\r\n",
      "--------------------------------------------------\r\n",
      "  Loading fresh model...\r\n",
      "============================================================\r\n",
      "SparseAdapter Parameter Summary\r\n",
      "============================================================\r\n",
      "Total parameters:     540,444,544\r\n",
      "Trainable parameters: 46,411,776\r\n",
      "Trainable ratio:      8.5877%\r\n",
      "------------------------------------------------------------\r\n",
      "  Sparse MLP: 46,424,064\r\n",
      "============================================================\r\n",
      "\r\n",
      "  Training SparseAdapter...\r\n",
      "Starting training for 1 epochs\r\n",
      "Total steps: 62\r\n",
      "Device: cuda\r\n",
      "Epoch 1: 100%|████| 1000/1000 [08:52<00:00,  1.88it/s, loss=5.1659, lr=3.93e-05]\r\n",
      "  Evaluating sparse...\r\n",
      "    Evaluating perplexity...\r\n",
      "Evaluating: 100%|█████████████████████████████| 100/100 [00:09<00:00, 10.50it/s]\r\n",
      "    Evaluating lost-in-middle...\r\n",
      "Lost-in-Middle Analysis: 100%|██████████████████| 20/20 [00:01<00:00, 14.07it/s]\r\n",
      "  ✗ Error with sparse: unsupported format string passed to EvaluationResult.__format__\r\n",
      "\r\n",
      "[8] Running HYLORADA...\r\n",
      "--------------------------------------------------\r\n",
      "  Loading fresh model...\r\n",
      "============================================================\r\n",
      "HyLoRADA Parameter Summary\r\n",
      "============================================================\r\n",
      "Total parameters:     541,548,064\r\n",
      "Trainable parameters: 47,515,296\r\n",
      "Trainable ratio:      8.7740%\r\n",
      "------------------------------------------------------------\r\n",
      "Component Breakdown:\r\n",
      "  LoRA:       1,081,344 (2.3% of trainable)\r\n",
      "  DAA:        22,848 (0.0% of trainable)\r\n",
      "  Sparse MLP: 46,424,064 (97.7% of trainable)\r\n",
      "============================================================\r\n",
      "\r\n",
      "  Training HyLoRADA...\r\n",
      "Starting training for 1 epochs\r\n",
      "Total steps: 62\r\n",
      "Device: cuda\r\n",
      "Epoch 1: 100%|████| 1000/1000 [10:05<00:00,  1.65it/s, loss=2.5272, lr=3.93e-05]\r\n",
      "Saved HyLoRADA weights to ./output/epoch_1/hylorada_weights.pt\r\n",
      "Saved HyLoRADA weights to ./output/epoch_1/hylorada_weights.pt\r\n",
      "Saved HyLoRADA weights to ./output/final/hylorada_weights.pt\r\n",
      "Saved HyLoRADA weights to ./output/final/hylorada_weights.pt\r\n",
      "  Evaluating hylorada...\r\n",
      "    Evaluating perplexity...\r\n",
      "Evaluating: 100%|█████████████████████████████| 100/100 [00:10<00:00,  9.22it/s]\r\n",
      "    Evaluating lost-in-middle...\r\n",
      "Lost-in-Middle Analysis: 100%|██████████████████| 20/20 [00:01<00:00, 12.32it/s]\r\n",
      "  ✗ Error with hylorada: unsupported format string passed to EvaluationResult.__format__\r\n",
      "\r\n",
      "======================================================================\r\n",
      "RESULTS SUMMARY\r\n",
      "======================================================================\r\n",
      "Method                Params   Train Time   Perplexity\r\n",
      "----------------------------------------------------------------------\r\n",
      "baseline               ERROR            -            -\r\n",
      "lora                   ERROR            -            -\r\n",
      "lorada                 ERROR            -            -\r\n",
      "longlora               ERROR            -            -\r\n",
      "sparse                 ERROR            -            -\r\n",
      "hylorada               ERROR            -            -\r\n",
      "======================================================================\r\n",
      "\r\n",
      "Results saved to: ./experiments/comparison_20260115_072915/comparison_results.json\r\n"
     ]
    }
   ],
   "source": [
    "# Compare all methods\n",
    "!python run_comparison.py --model_name Qwen/Qwen2-0.5B --max_length 1024 --num_epochs 1\n",
    "\n",
    "# Compare specific methods\n",
    "# !python run_comparison.py --methods lora lorada hylorada --num_epochs 3\n",
    "\n",
    "# Quick test\n",
    "# !python run_comparison.py --methods baseline lora hylorada --num_epochs 1 --num_test_samples 20\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3003.248093,
   "end_time": "2026-01-15T08:18:53.942074",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-15T07:28:50.693981",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
