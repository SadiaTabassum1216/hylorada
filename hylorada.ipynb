{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# HyLoRADA Experiments\n",
                "\n",
                "**HyLoRADA**: Hybrid Low-Rank Direct Attention Adaptation\n",
                "\n",
                "Novel contributions:\n",
                "1. **Orthogonal initialization** - Prevents rank collapse\n",
                "2. **Gated magnitude** - Learnable magnitude control\n",
                "3. **Residual LoRA path** - Blends DoRA + LoRA dynamics\n",
                "\n",
                "**Scripts:**\n",
                "- `run_benchmark.py` - Compare all PEFT methods\n",
                "- `optimize_hylorada.py` - Bayesian hyperparameter optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Suppress warnings\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import os\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "os.environ['GRPC_VERBOSITY'] = 'ERROR'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "clone",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repo\n",
                "!git clone https://github.com/SadiaTabassum1216/hylorada.git\n",
                "%cd hylorada"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "install",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers datasets accelerate tqdm optuna"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "check-gpu",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "benchmark-section",
            "metadata": {},
            "source": [
                "## 1. Run Benchmark (Recommended)\n",
                "\n",
                "Compare HyLoRADA against baselines (LoRA, DoRA, LoRaDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "benchmark",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare all PEFT methods\n",
                "!python run_benchmark.py \\\n",
                "    --model Qwen/Qwen2.5-0.5B \\\n",
                "    --max_length 1024 \\\n",
                "    --epochs 3 \\\n",
                "    --batch_size 1 \\\n",
                "    --grad_accum 16 \\\n",
                "    --num_train 1000 \\\n",
                "    --num_test 100 \\\n",
                "    --lora_rank 8 \\\n",
                "    --methods lora dora lorada hylorada \\\n",
                "    --output_dir ./benchmark_results"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "hpo-section",
            "metadata": {},
            "source": [
                "## 2. Hyperparameter Optimization (Optional)\n",
                "\n",
                "Uses Bayesian optimization (Optuna TPE) to find best hyperparameters:\n",
                "- `lora_rank`: [4, 8, 12, 16]\n",
                "- `alpha_ratio`: [1.5, 3.0]\n",
                "- `lora_plus_ratio`: [5, 20]\n",
                "- `base_lr`: [1e-5, 5e-4]\n",
                "- `gate_init`: [-1, 1]\n",
                "- `residual_init`: [0, 0.5]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "hpo",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run hyperparameter optimization (10 trials)\n",
                "!python optimize_hylorada.py \\\n",
                "    --n_trials 10 \\\n",
                "    --epochs 2 \\\n",
                "    --model Qwen/Qwen2.5-0.5B"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "optimized-section",
            "metadata": {},
            "source": [
                "## 3. Optimized HyLoRADA Config\n",
                "\n",
                "Use these optimized hyperparameters for best results:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "optimized-benchmark",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run with optimized hyperparameters\n",
                "# After HPO, update these values from optimization_results.json\n",
                "\n",
                "!python run_benchmark.py \\\n",
                "    --model Qwen/Qwen2.5-0.5B \\\n",
                "    --max_length 1024 \\\n",
                "    --epochs 3 \\\n",
                "    --batch_size 1 \\\n",
                "    --grad_accum 16 \\\n",
                "    --num_train 1000 \\\n",
                "    --num_test 100 \\\n",
                "    --lora_rank 12 \\\n",
                "    --methods dora hylorada \\\n",
                "    --output_dir ./optimized_results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "view-results",
            "metadata": {},
            "outputs": [],
            "source": [
                "# View HPO results\n",
                "import json\n",
                "try:\n",
                "    with open('optimization_results.json') as f:\n",
                "        results = json.load(f)\n",
                "    print(\"Best Hyperparameters:\")\n",
                "    for k, v in results['best_params'].items():\n",
                "        print(f\"  {k}: {v}\")\n",
                "    print(f\"\\nBest Loss: {results['best_value']:.4f}\")\n",
                "except:\n",
                "    print(\"Run HPO first to see results\")"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
