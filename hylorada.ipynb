{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# HyLoRADA: Software Evolution & Reengineering\n",
                "\n",
                "**HyLoRADA**: Hybrid Low-Rank Direct Attention Adaptation\n",
                "\n",
                "## Novel Contributions\n",
                "1. **Orthogonal initialization** - Prevents rank collapse\n",
                "2. **Gated magnitude** - Learnable magnitude control\n",
                "3. **Residual LoRA path** - Blends DoRA + LoRA dynamics\n",
                "\n",
                "## Evolution Path\n",
                "```\n",
                "LoRA (2021) → DoRA (2024) → HyLoRADA (2026)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Suppress warnings\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import os\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "os.environ['GRPC_VERBOSITY'] = 'ERROR'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "clone",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repo\n",
                "!git clone https://github.com/SadiaTabassum1216/hylorada.git\n",
                "%cd hylorada"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "install",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers datasets accelerate tqdm optuna"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "check-gpu",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "benchmark-section",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Run Benchmark on WikiText"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "benchmark-wikitext",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Benchmark on WikiText-2 (Language Modeling)\n",
                "!python run_benchmark.py \\\n",
                "    --model Qwen/Qwen2.5-0.5B \\\n",
                "    --dataset wikitext \\\n",
                "    --max_length 1024 \\\n",
                "    --epochs 3 \\\n",
                "    --batch_size 1 \\\n",
                "    --grad_accum 16 \\\n",
                "    --num_train 1000 \\\n",
                "    --num_test 100 \\\n",
                "    --methods lora dora lorada hylorada \\\n",
                "    --output_dir ./results_wikitext"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "code-section",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Run Benchmark on Code (Software Engineering Task)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "benchmark-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Benchmark on CodeSearchNet (Python Code Summarization)\n",
                "!python run_benchmark.py \\\n",
                "    --model Qwen/Qwen2.5-0.5B \\\n",
                "    --dataset code \\\n",
                "    --max_length 512 \\\n",
                "    --epochs 3 \\\n",
                "    --batch_size 1 \\\n",
                "    --grad_accum 16 \\\n",
                "    --num_train 1000 \\\n",
                "    --num_test 100 \\\n",
                "    --methods lora dora hylorada \\\n",
                "    --output_dir ./results_code"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "examples-section",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Generate Qualitative Examples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "generate-examples",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate comparison examples (code summarization + lost-in-middle)\n",
                "!python generate_examples.py \\\n",
                "    --checkpoint_dir ./results_wikitext \\\n",
                "    --output comparison_examples.md"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "view-examples",
            "metadata": {},
            "outputs": [],
            "source": [
                "# View the generated examples\n",
                "with open('comparison_examples.md', 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "hpo-section",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Hyperparameter Optimization (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "hpo",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bayesian optimization with Optuna (10 trials)\n",
                "!python optimize_hylorada.py --n_trials 10 --epochs 2"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "results-section",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. View Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "view-results",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "\n",
                "# Load WikiText results\n",
                "for results_dir in ['./results_wikitext', './results_code']:\n",
                "    results_file = os.path.join(results_dir, 'results.json')\n",
                "    if os.path.exists(results_file):\n",
                "        with open(results_file) as f:\n",
                "            results = json.load(f)\n",
                "        print(f\"\\n=== {results_dir} ===\")\n",
                "        for method, data in results.items():\n",
                "            if 'perplexity' in data:\n",
                "                print(f\"{method}: PPL={data['perplexity']:.2f}, Params={data.get('trainable_params', 'N/A'):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "download-results",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download results for report\n",
                "!zip -r hylorada_results.zip results_wikitext results_code comparison_examples.md METHODOLOGY.md"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}