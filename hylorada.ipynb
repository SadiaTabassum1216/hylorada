{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"header","cell_type":"markdown","source":"# HyLoRADA: Software Evolution & Reengineering\n\n## Novel Contributions\n1. **Orthogonal initialization** - Prevents rank collapse\n2. **Gated magnitude** - Learnable magnitude control\n3. **Residual LoRA path** - Blends DoRA + LoRA dynamics\n\n## Evolution Path\n```\nLoRA (2021) → DoRA (2024) → HyLoRADA (2026)\n```","metadata":{}},{"id":"setup","cell_type":"code","source":"# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['GRPC_VERBOSITY'] = 'ERROR'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T05:52:30.065634Z","iopub.execute_input":"2026-01-17T05:52:30.065953Z","iopub.status.idle":"2026-01-17T05:52:30.084317Z","shell.execute_reply.started":"2026-01-17T05:52:30.065917Z","shell.execute_reply":"2026-01-17T05:52:30.083340Z"}},"outputs":[],"execution_count":1},{"id":"clone","cell_type":"code","source":"# Clone repo\n!git clone https://github.com/SadiaTabassum1216/hylorada.git\n%cd hylorada","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T05:52:30.085771Z","iopub.execute_input":"2026-01-17T05:52:30.086057Z","iopub.status.idle":"2026-01-17T05:52:31.495068Z","shell.execute_reply.started":"2026-01-17T05:52:30.086030Z","shell.execute_reply":"2026-01-17T05:52:31.494291Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'hylorada'...\nremote: Enumerating objects: 150, done.\u001b[K\nremote: Counting objects: 100% (150/150), done.\u001b[K\nremote: Compressing objects: 100% (100/100), done.\u001b[K\nremote: Total 150 (delta 93), reused 104 (delta 47), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (150/150), 174.82 KiB | 1.88 MiB/s, done.\nResolving deltas: 100% (93/93), done.\n/kaggle/working/hylorada\n","output_type":"stream"}],"execution_count":2},{"id":"install","cell_type":"code","source":"!pip install -q transformers datasets accelerate tqdm optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T05:52:31.496303Z","iopub.execute_input":"2026-01-17T05:52:31.496541Z","iopub.status.idle":"2026-01-17T05:52:36.057301Z","shell.execute_reply.started":"2026-01-17T05:52:31.496515Z","shell.execute_reply":"2026-01-17T05:52:36.056352Z"}},"outputs":[],"execution_count":3},{"id":"check-gpu","cell_type":"code","source":"import torch\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T05:52:36.058651Z","iopub.execute_input":"2026-01-17T05:52:36.059017Z","iopub.status.idle":"2026-01-17T05:52:39.799577Z","shell.execute_reply.started":"2026-01-17T05:52:36.058978Z","shell.execute_reply":"2026-01-17T05:52:39.798769Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nGPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":4},{"id":"code-section","cell_type":"markdown","source":"---\n## 2. Run Benchmark on Code","metadata":{}},{"id":"bfbc635c-26a2-4292-b9e1-7dd54eb2bfdc","cell_type":"code","source":"!python run_benchmark.py --dataset code --methods lora dora hylorada --epochs 3 --output_dir ./results_code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T05:52:39.805763Z","iopub.execute_input":"2026-01-17T05:52:39.806033Z","execution_failed":"2026-01-17T06:21:30.708Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nPEFT Methods Benchmark\n======================================================================\nModel: Qwen/Qwen2-0.5B\nDataset: code\nMethods: lora, dora, hylorada\nHyperparameters: epochs=3, batch=1, lr=0.0002\nMax Length: 1024, LoRA Rank: 8\n======================================================================\n\n[1] Loading tokenizer...\ntokenizer_config.json: 1.29kB [00:00, 6.10MB/s]\nvocab.json: 2.78MB [00:00, 100MB/s]\nmerges.txt: 1.67MB [00:00, 143MB/s]\ntokenizer.json: 7.03MB [00:00, 188MB/s]\n[2] Loading data...\nREADME.md: 33.2kB [00:00, 90.8MB/s]\n    Warning: Code dataset failed (BuilderConfig 'humaneval-py' not found. Available: ['humaneval-adb', 'humaneval-clj', 'humaneval-cpp', 'humaneval-cs', 'humaneval-d', 'humaneval-dart', 'humaneval-elixir', 'humaneval-go', 'humaneval-hs', 'humaneval-java', 'humaneval-jl', 'humaneval-js', 'humaneval-lua', 'humaneval-ml', 'humaneval-php', 'humaneval-pl', 'humaneval-r', 'humaneval-rb', 'humaneval-rkt', 'humaneval-rs', 'humaneval-scala', 'humaneval-sh', 'humaneval-swift', 'humaneval-ts', 'mbpp-adb', 'mbpp-clj', 'mbpp-cpp', 'mbpp-cs', 'mbpp-d', 'mbpp-elixir', 'mbpp-go', 'mbpp-hs', 'mbpp-java', 'mbpp-jl', 'mbpp-js', 'mbpp-lua', 'mbpp-ml', 'mbpp-php', 'mbpp-pl', 'mbpp-r', 'mbpp-rb', 'mbpp-rkt', 'mbpp-rs', 'mbpp-scala', 'mbpp-sh', 'mbpp-swift', 'mbpp-ts']), falling back to WikiText\nREADME.md: 10.5kB [00:00, 42.4MB/s]\nwikitext-2-raw-v1/test-00000-of-00001.pa(…): 100%|█| 733k/733k [00:01<00:00, 617\nwikitext-2-raw-v1/train-00000-of-00001.p(…): 100%|█| 6.36M/6.36M [00:00<00:00, 7\nwikitext-2-raw-v1/validation-00000-of-00(…): 100%|█| 657k/657k [00:00<00:00, 1.6\nGenerating test split: 100%|██████| 4358/4358 [00:00<00:00, 91500.48 examples/s]\nGenerating train split: 100%|██| 36718/36718 [00:00<00:00, 748472.52 examples/s]\nGenerating validation split: 100%|█| 3760/3760 [00:00<00:00, 661323.56 examples/\n    Dataset: WikiText-2 (fallback)\n    Train: 1000, Test: 100\n\n[3] Running LORA...\n--------------------------------------------------\n  Loading fresh model...\nconfig.json: 100%|█████████████████████████████| 661/661 [00:00<00:00, 7.11MB/s]\n`torch_dtype` is deprecated! Use `dtype` instead!\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768629186.846304     117 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768629186.901294     117 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768629187.392826     117 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768629187.392885     117 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768629187.392889     117 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768629187.392892     117 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nmodel.safetensors: 100%|██████████████████████| 988M/988M [00:03<00:00, 269MB/s]\ngeneration_config.json: 100%|██████████████████| 138/138 [00:00<00:00, 1.34MB/s]\n============================================================\nStandard LoRA Parameter Summary\n============================================================\nTotal parameters:     494,573,440\nTrainable parameters: 540,672\nTrainable ratio:      0.1093%\n------------------------------------------------------------\n  LoRA: 540,672\n============================================================\n  Training LoRA...\nStarting training for 3 epochs\nTotal steps: 186\nDevice: cuda\nEpoch 1: 100%|████| 1000/1000 [08:59<00:00,  1.85it/s, loss=4.4328, lr=1.50e-04]\nEpoch 2: 100%|████| 1000/1000 [08:58<00:00,  1.86it/s, loss=0.4685, lr=9.50e-05]\nEpoch 3: 100%|████| 1000/1000 [08:58<00:00,  1.86it/s, loss=0.4452, lr=3.98e-05]\n  Evaluating lora...\n    Evaluating perplexity...\nEvaluating: 100%|█████████████████████████████| 100/100 [00:08<00:00, 12.00it/s]\n    Evaluating lost-in-middle...\nLost-in-Middle Analysis: 100%|██████████████████| 20/20 [00:01<00:00, 16.25it/s]\n  ✓ lora: PPL=28.43, Params=540,672, Time=1617.9s\n  ✗ Error: Parent directory ./results_code does not exist.\n\n[4] Running DORA...\n--------------------------------------------------\n  Loading fresh model...\n============================================================\nHyLoRADA Parameter Summary\n============================================================\nTotal parameters:     495,163,264\nTrainable parameters: 1,130,496\nTrainable ratio:      0.2283%\n------------------------------------------------------------\nComponent Breakdown:\n  LoRA:       0 (0.0% of trainable)\n  DAA:        0 (0.0% of trainable)\n  Sparse MLP: 0 (0.0% of trainable)\n============================================================\n  Training DoRA...\nStarting training for 3 epochs\nTotal steps: 186\nDevice: cuda\nEpoch 1:   9%|██▉                             | 92/1000 [00:57<09:23,  1.61it/s]","output_type":"stream"}],"execution_count":null},{"id":"examples-section","cell_type":"markdown","source":"---\n## 3. Generate Qualitative Examples","metadata":{}},{"id":"294d871a-aadd-4270-a75b-52dfc6886a14","cell_type":"code","source":"!python generate_examples.py \\\n    --checkpoint_dir ./results_code \\\n    --output comparison_examples.md","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-17T06:21:30.709Z"}},"outputs":[],"execution_count":null},{"id":"view-examples","cell_type":"code","source":"# View the generated examples\nwith open('comparison_examples.md', 'r') as f:\n    print(f.read())","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-17T06:21:30.709Z"}},"outputs":[],"execution_count":null},{"id":"results-section","cell_type":"markdown","source":"---\n## 5. View Results","metadata":{}},{"id":"view-results","cell_type":"code","source":"import json\nimport os\n\n# Load WikiText results\n# for results_dir in ['./results_wikitext', './results_code']:\nfor results_dir in ['./results_code']:\n    results_file = os.path.join(results_dir, 'results.json')\n    if os.path.exists(results_file):\n        with open(results_file) as f:\n            results = json.load(f)\n        print(f\"\\n=== {results_dir} ===\")\n        for method, data in results.items():\n            if 'perplexity' in data:\n                print(f\"{method}: PPL={data['perplexity']:.2f}, Params={data.get('trainable_params', 'N/A'):,}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-17T06:21:30.709Z"}},"outputs":[],"execution_count":null},{"id":"download-results","cell_type":"code","source":"# Download results for report\n!zip -r hylorada_results.zip results_code comparison_examples.md","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-17T06:21:30.709Z"}},"outputs":[],"execution_count":null}]}