{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# HyLoRADA Experiments\n",
                "\n",
                "This notebook runs HyLoRADA training, evaluation, and benchmarks on Kaggle.\n",
                "\n",
                "**Scripts:**\n",
                "- `train_hylorada.py` - Train HyLoRADA model\n",
                "- `evaluate_hylorada.py` - Evaluate trained model\n",
                "- `run_benchmark.py` - Compare all PEFT methods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Suppress warnings\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import os\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "os.environ['GRPC_VERBOSITY'] = 'ERROR'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "clone",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repo\n",
                "!git clone https://github.com/SadiaTabassum1216/hylorada.git\n",
                "%cd hylorada"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "install",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers datasets accelerate tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "check-gpu",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "train-section",
            "metadata": {},
            "source": [
                "## Option 1: Train HyLoRADA Only"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train HyLoRADA model\n",
                "!python train_hylorada.py \\\n",
                "    --model Qwen/Qwen2-0.5B \\\n",
                "    --max_length 1024 \\\n",
                "    --epochs 3 \\\n",
                "    --batch_size 1 \\\n",
                "    --grad_accum 16 \\\n",
                "    --num_samples 1000 \\\n",
                "    --output_dir ./output"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eval-section",
            "metadata": {},
            "source": [
                "## Option 2: Evaluate Trained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "evaluate",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate trained HyLoRADA model\n",
                "!python evaluate_hylorada.py \\\n",
                "    --model Qwen/Qwen2-0.5B \\\n",
                "    --weights ./output/final/hylorada_weights.pt \\\n",
                "    --max_length 1024 \\\n",
                "    --num_samples 100"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "benchmark-section",
            "metadata": {},
            "source": [
                "## Option 3: Run Full Benchmark (All Methods)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "benchmark",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare all PEFT methods with same hyperparameters\n",
                "!python run_benchmark.py \\\n",
                "    --model Qwen/Qwen2-0.5B \\\n",
                "    --max_length 1024 \\\n",
                "    --epochs 1 \\\n",
                "    --batch_size 1 \\\n",
                "    --grad_accum 16 \\\n",
                "    --num_train 1000 \\\n",
                "    --num_test 100 \\\n",
                "    --lora_rank 8 \\\n",
                "    --output_dir ./benchmark_results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "benchmark-subset",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare specific methods only\n",
                "# !python run_benchmark.py --model Qwen/Qwen2-0.5B --epochs 3 --methods lora lorada hylorada"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}